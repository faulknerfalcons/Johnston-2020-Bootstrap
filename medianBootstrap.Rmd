---
title: "Example use and extensions of medianBootstrap.R"
author: "MG Johnston"
date: "25/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = F) 
knitr::opts_chunk$set(warning = F)
setwd("E:/Letterv3/")
set.seed(1)
```

## Introduction 

This is short primer on the use of medianBootstrap for the analysis of cell-to-cell spread data, using an example from Cheval et al. (2020) under CC BY 4.0.

Currently, most of the literature uses a Mann-Whitney-Wilcox test to analyse GFP cell-to-cell spread data. Here, we propose a medianBootstrap method, which accounts for the varying shape and variance between control and treatment/genotype conditions. 

## Example Use

```{r introduction}
## Load functions from medianBootstrap.R

# source(medianBootstrap.R)
# or

mcp_ci <- function(success, trials, alpha){
  ## Copyright (C) 2001 Frank E Harrell Jr
  ## Modified by Matthew G Johnston 2020 from binconf in the Hmisc package
  ## Distributed under GNU General Public License v2 (or later) without any warranty. See the GNU General Public License for more details.
  zcrit <-  - qnorm(alpha/2)
  z2 <- zcrit * zcrit
  mc_p <- success/trials
  cl <- (mc_p + z2/2/trials + c(-1, 1) * zcrit *
           sqrt((mc_p * (1 - mc_p) + z2/4/trials)/trials))/(1 + z2/trials)
  if(success == 1)
    cl[1] <-  - log(1 - alpha)/trials
  if(success == (trials - 1))
    cl[2] <- 1 + log(1 - alpha)/trials
  return(cbind(mc_p, lower_ci=cl[1], upper_ci=cl[2]))
}

medianBootstrap<- function(data1, data2, N=5000, alpha=0.05){
  ## Calculate observed test statistic
  mediandiff<-median(data1)-median(data2)
  ## Generate the null distribution
  boots<-replicate(N, median(sample(data1,length(data1), replace=T))-median(sample(data2,length(data2),  replace=T))-mediandiff)
  ## Count the number of at resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(mediandiff))
  ## Calculate p value and confidence intervals
  mcp<-mcp_ci(above+1,N+1, alpha)
  return(mcp)
}

## Load example data from Cheval et al. (2020)
library(readxl)
ChevalCount <- read_excel("Letter.xlsx",
                          sheet = 1, col_names = T)

## Extract the relevant data into two vectors and plot them
Mock <- ChevalCount[ChevalCount$treatment=="Mock",]$movement
Chitin <- ChevalCount[ChevalCount$treatment=="Chitin",]$movement
par(mfrow=c(1,2))
hist(Mock)
hist(Chitin)

## Run the statistical test
medianBootstrap(Mock,Chitin, N=5000, alpha=0.05)
```

## More accurate confidence intervals

We can see here, that the two distributions are remarkably different. By using further bootstraps, we can refine the Monte Carlo p value and reduce the confidence intervals.

```{r moreBoots}
## Run the statistical test with more bootstraps
medianBootstrap(Mock,Chitin, N=25000, alpha=0.05)
```

Instead of using Wilson (1927) confidence intervals, a boostrap 95% confidence interval can be constructed: 

```{r diffCI}
## Generate bootstraped 95% confidence intervals

medianBootstrap_once<- function(data1, data2, N=5000, alpha=0.05){
  ## Calculate observed test statistic
  mediandiff<-median(data1)-median(data2)
  ## Generate the null distribution
  boots<-replicate(N, median(sample(data1,length(data1), replace=T))-median(sample(data2,length(data2),  replace=T))-mediandiff)
  ## Count the number of at resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(mediandiff))
  ## Calculate p value
  mcp<-(above+1)/(N+1)
  return(mcp)
}

pvalue<-medianBootstrap_once(Mock,Chitin, N=5000, alpha=0.05)
interval<-replicate(100,medianBootstrap_once(Mock,Chitin, N=5000, alpha=0.05))

paste("p =", format(round(pvalue,5),nsmall=5), ", 95% CI = [", format(round(quantile(interval, c(0.025)),5),nsmall=5),",",format(round(quantile(interval, c(0.975)),5),nsmall=5),"]")

```

## Plotting the null distribution

You may be interested to also view the null distribution generated by the medianBootstrap script. I provide an example function for this here.

```{r plotNull}
library(ggplot2)
medianBootstrap_plot<- function(data1, data2, N=5000, alpha=0.05){
  ## Calculate observed test statistic
  mediandiff<-median(data1)-median(data2)
  ## Generate the null distribution
  boots<-replicate(N, median(sample(data1,length(data1), replace=T))-median(sample(data2,length(data2),  replace=T))-mediandiff)
  ## Count the number of at resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(mediandiff))
  ## Calculate p value and confidence intervals
  mcp<-format(round(mcp_ci(above+1,N+1, alpha),3),nsmall=3)
  ## Plot graph
  labeltext1<- substitute(atop(paste(hat(italic("p")))~phantom()==phantom()~AAA,"95% CI"~BBB~CCC), list(AAA=mcp[1], BBB =paste0("[",mcp[2],", "), CCC= paste0(mcp[3],"]")))
  plot<-ggplot(data.frame(median=boots), aes(x=abs(median)))+
    geom_histogram(alpha=.7, binwidth = 1, aes(y=..density..))+
    geom_vline(xintercept = abs(mediandiff), linetype=2, colour = "red4")+
    theme_bw()+
    xlab(expression(atop("|"~hat(paste(theta, "*"))~-~hat(theta)~"|",theta==Delta[median])))+
    ylab("Density")+
    annotate("text",x = Inf, y = Inf, hjust = 1.1, vjust = 1.1,label=labeltext1)+
    theme(text=element_text(size=15))
  return(plot)
}

medianBootstrap_plot(Mock,Chitin, N=5000, alpha=0.05)
```

## Extending the method to multiple comparisons
It is rare that we want to compare a control to only one treatment. Therefore, a method to control family-wise error rate is required. The below function will compare an unlimited number of vectors to the first and then perform a Holm correction (Holm, 1797).

```{r multipleBoots}

medianBootstraps<- function(..., N=5000, alpha=0.05){
results<-NULL
x<-list(...)
reference<-x[[1]]
  for(i in 2:(length(x))){
  ## Calculate observed test statistic
  mediandiff<-median(reference)-median(x[[i]])
  ## Generate the null distribution
  boots<-replicate(N, median(sample(reference,length(reference), replace=T))-median(sample(x[[i]],length(x[[i]]), replace=T))-mediandiff)
  ## Count the number of at resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(mediandiff))
  ## Calculate p value and confidence intervals
  mcp<-mcp_ci(above+1,N+1, alpha)
  results<-rbind(results, mcp)
}
## Calculate observed test statistics
return(cbind(pvaladj=p.adjust(results[,1]),pvaladj_lower=p.adjust(results[,2]),pvaladj_upper=p.adjust(results[,3])))
}

medianBootstraps(Mock,Chitin[1:100],Chitin[101:200],Chitin[201:300], N=5000, alpha=0.05)
```

## Extending the method to the mean

```{r mean}
meanBootstrap<- function(data1, data2, N=5000, alpha=0.05){
  ## Calculate observed test statistic
  meandiff<-mean(data1)-mean(data2)
  ## Generate the null distribution
  boots<-replicate(N, mean(sample(data1,length(data1), replace=T))-mean(sample(data2,length(data2),  replace=T))-meandiff)
  ## Count the number of at resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(meandiff))
  ## Calculate p value and confidence intervals
  mcp<-mcp_ci(above+1,N+1, alpha)
  return(mcp)
}
meanBootstrap(Mock,Chitin, N=5000, alpha=0.05)
```

## Why do we subtract the observed median from the resamples?

To generate the null distribution, the function subtracts the observed median difference from the resampled median difference. This is done so as to correct the data so that the statistical test is conducted with H0 being true (that there is no difference in medians).

This a long hand way of doing this, where the datasets are recentred first to have their medians made the same (e.g. around 0). This is done below and compared to the method presented in the letter.

```{r longBoot}
medianBootstrap_long_plot<- function(data1, data2, N=5000, alpha=0.05){
  ## Calculate observed test statistic
  mediandiff<-median(data1)-median(data2)
  
  ## Make H0 true (make the median of both vectors 0)
  new_data1 <- data1-median(data1)
  new_data2 <- data2-median(data2)
  
  ## Generate the null distribution
  boots<-replicate(N, median(sample(new_data1,length(new_data1), replace=T))-median(sample(new_data2,length(new_data2), replace=T)))
  ## Count the number of resampled observations which are at least as extreme
  above <- sum(abs(boots)>=abs(mediandiff))
  ## Calculate p value and confidence intervals
  mcp<-format(round(mcp_ci(above+1,N+1, alpha),3),nsmall=3)
  ## Plot the graph
  labeltext1<- substitute(atop(paste(hat(italic("p")))~phantom()==phantom()~AAA,"95% CI"~BBB~CCC), list(AAA=mcp[1], BBB =paste0("[",mcp[2],", "), CCC= paste0(mcp[3],"]")))
  plot<-ggplot(data.frame(median=boots), aes(x=abs(median)))+
    geom_histogram(alpha=.7, binwidth = 1, aes(y=..density..))+
    geom_vline(xintercept = abs(mediandiff), linetype=2, colour = "red4")+
    theme_bw()+
    xlab(expression(atop("|"~hat(paste(theta[centred], "*"))~"|",theta==Delta[median])))+
    ylab("Density")+
    annotate("text",x = Inf, y = Inf, hjust = 1.1, vjust = 1.1,label=labeltext1)+
    theme(text=element_text(size=15))
  return(plot)
}

set.seed(123)
original<-medianBootstrap_plot(Mock,Chitin, N=5000, alpha=0.05)+ggtitle("Subtract observed diff")
set.seed(123)
recentre<-medianBootstrap_long_plot(Mock,Chitin, N=5000, alpha=0.05)+ggtitle("Recentre first")

library(gridExtra)
grid.arrange(original,recentre, ncol=2)
```

## References

C. Cheval et al., Chitin perception in plasmodesmata characterises submembrane immune signalling specificity in plants. PNAS, 117(17):9621–29, 2020.

S. Holm, A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6:65–70, 1979.

E.B. Wilson, Probable Inference, the Law of Succession, and Statistical Inference. Journal of the American Statistical Association 22: 209–12, 1927.

## Session Information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```